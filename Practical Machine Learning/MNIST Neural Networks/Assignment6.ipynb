{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 422 Assignment #6 - Artificial Neural Networks\n",
    "\n",
    "**Table of contents:**\n",
    "\n",
    "* System & Data Setup\n",
    "* Model 1 - 2 layer model - 10 neurons per layer\n",
    "* Model 2 - 2 layer model - 20 neurons per layer\n",
    "* Model 3 - 5 layer model - 10 neurons per layer\n",
    "* Model 4 - 5 layer model - 20 neurons per layer\n",
    "* Model 5 - 2 layer model - 300 neurons per layer\n",
    "* Model 6 - 3 layer model - 300 neurons per layer\n",
    "* Model 7 - 2 layer model - 150 neurons per layer\n",
    "* Model 8 - 3 layer model - 150 neurons per layer\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#suppress tf.logging\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\isabe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "#Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train & test data\n",
    "(X_train1, y_train), (X_test1, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train1 = X_train1.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test1 = X_test1.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test split 'train'\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test split 'test'\n",
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (60000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check data in training set as visual:\n",
    "print('Training data shape', X_train1.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train1[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train1[1].reshape(28, 28), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define confusion matrix plot\n",
    "def plot_confusion_matrix(matrix):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.23529419e-06 3.07189544e-05 1.41176472e-05 5.88235321e-07\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.04575170e-06 3.59477134e-06 3.64052301e-05 9.52287595e-05\n",
      " 1.71437911e-04 2.51372554e-04 4.71111118e-04 6.30326806e-04\n",
      " 6.83071906e-04 6.95817004e-04 7.42418314e-04 6.82941185e-04\n",
      " 7.33071908e-04 6.02549029e-04 3.92614386e-04 2.79346409e-04\n",
      " 2.11045755e-04 8.37908509e-05 3.95424849e-05 1.38562094e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.18300678e-06 2.74509806e-06\n",
      " 2.72549031e-05 2.15032683e-05 1.84705886e-04 5.42745108e-04\n",
      " 1.03601309e-03 1.98673206e-03 3.39921573e-03 5.05915041e-03\n",
      " 7.33470599e-03 9.92137269e-03 1.25553597e-02 1.42178433e-02\n",
      " 1.45960133e-02 1.33041178e-02 1.09918956e-02 8.01718964e-03\n",
      " 4.71418307e-03 2.48411768e-03 1.16143793e-03 3.68562098e-04\n",
      " 1.38104578e-04 3.38562099e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.26797391e-05 2.29411773e-05\n",
      " 4.71241839e-05 2.73594777e-04 8.31699362e-04 2.14156866e-03\n",
      " 4.52712425e-03 8.68980404e-03 1.42730721e-02 2.13254905e-02\n",
      " 2.90472553e-02 3.80264057e-02 4.66003274e-02 5.19112424e-02\n",
      " 5.14690856e-02 4.63275169e-02 3.74261443e-02 2.69139219e-02\n",
      " 1.64456865e-02 8.92013083e-03 4.16091510e-03 1.61986931e-03\n",
      " 6.35620927e-04 1.08888892e-04 1.09803922e-05 0.00000000e+00\n",
      " 0.00000000e+00 2.48366023e-06 2.04575171e-05 5.62745112e-05\n",
      " 3.17189549e-04 1.60869284e-03 4.09111118e-03 9.48738578e-03\n",
      " 1.87284316e-02 3.29192815e-02 5.21971249e-02 7.63815696e-02\n",
      " 1.06026210e-01 1.38086930e-01 1.64081570e-01 1.77461178e-01\n",
      " 1.73877780e-01 1.53495884e-01 1.22855753e-01 8.98977789e-02\n",
      " 5.81608504e-02 3.39662750e-02 1.78351637e-02 8.38045765e-03\n",
      " 3.38392163e-03 8.14705903e-04 1.16274513e-04 7.97385623e-06\n",
      " 0.00000000e+00 0.00000000e+00 4.04575177e-05 2.48431378e-04\n",
      " 1.55084971e-03 5.73882362e-03 1.40697388e-02 2.83443795e-02\n",
      " 5.10475170e-02 8.32075173e-02 1.23530982e-01 1.73358302e-01\n",
      " 2.30995492e-01 2.89428042e-01 3.33736212e-01 3.55293271e-01\n",
      " 3.48721310e-01 3.14436277e-01 2.58599284e-01 1.95269937e-01\n",
      " 1.34705230e-01 8.43529422e-02 4.85894778e-02 2.60357520e-02\n",
      " 1.17361440e-02 3.30849681e-03 5.55424850e-04 1.84313731e-05\n",
      " 0.00000000e+00 7.18954268e-07 1.07843139e-04 8.68366028e-04\n",
      " 4.39026151e-03 1.29015688e-02 2.91626148e-02 5.58997392e-02\n",
      " 9.46578442e-02 1.46229479e-01 2.08295688e-01 2.78089480e-01\n",
      " 3.50111637e-01 4.16599873e-01 4.64729873e-01 4.86659415e-01\n",
      " 4.77299350e-01 4.39346409e-01 3.76894578e-01 2.94766146e-01\n",
      " 2.11910263e-01 1.38480328e-01 8.23211774e-02 4.48722882e-02\n",
      " 2.11284971e-02 7.27679752e-03 1.46156866e-03 1.18823533e-04\n",
      " 3.07189549e-06 7.73856230e-05 4.22222229e-04 2.33588239e-03\n",
      " 9.06823543e-03 2.32500657e-02 4.87688241e-02 8.80462755e-02\n",
      " 1.42332485e-01 2.11366342e-01 2.89273401e-01 3.69031703e-01\n",
      " 4.37566605e-01 4.90195756e-01 5.20623991e-01 5.30975298e-01\n",
      " 5.22896671e-01 4.96774644e-01 4.45281049e-01 3.67624578e-01\n",
      " 2.73638957e-01 1.83658368e-01 1.10368302e-01 5.96119616e-02\n",
      " 2.75830070e-02 1.01295427e-02 2.01215691e-03 1.25032683e-04\n",
      " 1.59477127e-05 1.99281049e-04 1.29163401e-03 5.16607851e-03\n",
      " 1.46985623e-02 3.32684971e-02 6.59536609e-02 1.16068237e-01\n",
      " 1.84039806e-01 2.67086277e-01 3.54083859e-01 4.25394971e-01\n",
      " 4.68374187e-01 4.83897455e-01 4.82502161e-01 4.79767259e-01\n",
      " 4.81294317e-01 4.78996474e-01 4.55925232e-01 3.94551376e-01\n",
      " 3.03207976e-01 2.07441571e-01 1.24747518e-01 6.41477132e-02\n",
      " 2.81790854e-02 1.02220263e-02 1.88856213e-03 1.06601310e-04\n",
      " 1.90849678e-05 3.11633992e-04 2.00790853e-03 6.74267982e-03\n",
      " 1.74345754e-02 3.84573861e-02 7.65744453e-02 1.35313008e-01\n",
      " 2.14513335e-01 3.06423663e-01 3.88387062e-01 4.33727324e-01\n",
      " 4.34460984e-01 4.10014186e-01 3.88420395e-01 3.89758369e-01\n",
      " 4.09149873e-01 4.34831638e-01 4.35601049e-01 3.88811441e-01\n",
      " 3.02119806e-01 2.06689283e-01 1.23327125e-01 6.03635955e-02\n",
      " 2.33769938e-02 7.44300667e-03 1.37973859e-03 1.10653596e-04\n",
      " 2.61437913e-05 3.86535953e-04 2.05111114e-03 6.56699354e-03\n",
      " 1.68199348e-02 3.87311116e-02 8.05463408e-02 1.45839348e-01\n",
      " 2.34176930e-01 3.27053859e-01 3.93042748e-01 4.04583598e-01\n",
      " 3.68204448e-01 3.25305167e-01 3.11462095e-01 3.31470657e-01\n",
      " 3.68112095e-01 4.09519742e-01 4.16788958e-01 3.69497519e-01\n",
      " 2.81761048e-01 1.89479414e-01 1.11679151e-01 5.29339876e-02\n",
      " 1.80411767e-02 4.51019616e-03 8.69934658e-04 7.34640542e-05\n",
      " 2.32679748e-05 2.99607848e-04 1.65052290e-03 5.02104582e-03\n",
      " 1.42983662e-02 3.74662750e-02 8.28754258e-02 1.56292224e-01\n",
      " 2.51330264e-01 3.41998696e-01 3.87374840e-01 3.72026866e-01\n",
      " 3.20327585e-01 2.87618696e-01 2.98608107e-01 3.35002160e-01\n",
      " 3.81540396e-01 4.21500330e-01 4.13762487e-01 3.49135297e-01\n",
      " 2.54683728e-01 1.66654446e-01 9.93768638e-02 4.93341836e-02\n",
      " 1.56466016e-02 2.37071900e-03 4.88235303e-04 3.20261447e-05\n",
      " 1.49019614e-05 1.71307193e-04 9.49150342e-04 3.44633992e-03\n",
      " 1.20346407e-02 3.76762750e-02 8.93254258e-02 1.70882485e-01\n",
      " 2.70475819e-01 3.53947846e-01 3.83897323e-01 3.57187193e-01\n",
      " 3.12575493e-01 3.11251441e-01 3.50347846e-01 3.98880461e-01\n",
      " 4.43285755e-01 4.61102357e-01 4.21281245e-01 3.31446604e-01\n",
      " 2.29753597e-01 1.50052747e-01 9.30950336e-02 4.98513731e-02\n",
      " 1.68420264e-02 1.73823533e-03 3.12875823e-04 3.98692820e-05\n",
      " 2.09150339e-06 7.15686285e-05 4.80849679e-04 2.38169938e-03\n",
      " 1.14424838e-02 4.17026149e-02 1.00210981e-01 1.86602812e-01\n",
      " 2.84832290e-01 3.59504513e-01 3.79954578e-01 3.57246016e-01\n",
      " 3.40656081e-01 3.80260984e-01 4.36752290e-01 4.86164971e-01\n",
      " 5.09045298e-01 4.96468827e-01 4.26981703e-01 3.18265232e-01\n",
      " 2.16572028e-01 1.45900394e-01 9.40109813e-02 5.35049025e-02\n",
      " 2.00105232e-02 2.29294122e-03 3.25424844e-04 4.26143795e-05\n",
      " 7.38562097e-06 3.23529416e-05 2.12418304e-04 1.82816996e-03\n",
      " 1.20218956e-02 4.84363405e-02 1.11874772e-01 1.98072093e-01\n",
      " 2.89218107e-01 3.54388957e-01 3.72850918e-01 3.65837389e-01\n",
      " 3.83642945e-01 4.52632618e-01 5.10851964e-01 5.47269024e-01\n",
      " 5.37649546e-01 5.02297062e-01 4.19586343e-01 3.11976277e-01\n",
      " 2.19986538e-01 1.52717910e-01 1.00146929e-01 5.73186280e-02\n",
      " 2.24375820e-02 3.21686280e-03 3.62549027e-04 8.69281058e-06\n",
      " 2.87581710e-06 1.51633988e-05 1.76862749e-04 1.98267977e-03\n",
      " 1.39630067e-02 5.65025497e-02 1.21522812e-01 2.00822093e-01\n",
      " 2.80158564e-01 3.36204774e-01 3.58356996e-01 3.69578173e-01\n",
      " 4.11949481e-01 4.83153729e-01 5.32115428e-01 5.45529612e-01\n",
      " 5.16880396e-01 4.76221833e-01 3.97412944e-01 3.07369676e-01\n",
      " 2.28560394e-01 1.61768368e-01 1.05804380e-01 5.83945104e-02\n",
      " 2.28560134e-02 4.23359484e-03 5.81241842e-04 4.24836611e-05\n",
      " 2.61437918e-06 1.55555559e-05 2.91503274e-04 2.44300658e-03\n",
      " 1.75292813e-02 6.48194779e-02 1.27666341e-01 1.95861701e-01\n",
      " 2.60045950e-01 3.05436342e-01 3.28262944e-01 3.50778108e-01\n",
      " 3.96611833e-01 4.54342748e-01 4.95974186e-01 4.99712357e-01\n",
      " 4.74732618e-01 4.36149415e-01 3.74009154e-01 3.03352094e-01\n",
      " 2.33754250e-01 1.64864054e-01 1.04818694e-01 5.58553601e-02\n",
      " 2.20217650e-02 5.04745106e-03 7.50980409e-04 4.82352953e-05\n",
      " 0.00000000e+00 2.85620927e-05 4.40000008e-04 3.73862751e-03\n",
      " 2.33420918e-02 7.26447067e-02 1.31181178e-01 1.88926864e-01\n",
      " 2.37100133e-01 2.71443270e-01 2.92868303e-01 3.16614513e-01\n",
      " 3.51319807e-01 3.99805559e-01 4.41633337e-01 4.52693794e-01\n",
      " 4.40175820e-01 4.09898631e-01 3.63241506e-01 3.02986212e-01\n",
      " 2.32660852e-01 1.60032551e-01 9.78147069e-02 5.03325496e-02\n",
      " 2.02221572e-02 5.55555565e-03 8.23660149e-04 3.48366020e-05\n",
      " 7.45098046e-06 2.08496736e-05 7.07843149e-04 5.96137264e-03\n",
      " 2.98880396e-02 8.00700662e-02 1.36905230e-01 1.88951244e-01\n",
      " 2.28536669e-01 2.58801832e-01 2.81359349e-01 3.00326604e-01\n",
      " 3.25969414e-01 3.73058565e-01 4.17871376e-01 4.40005428e-01\n",
      " 4.36658566e-01 4.11836409e-01 3.67131702e-01 3.00499741e-01\n",
      " 2.22357192e-01 1.48088498e-01 8.84184977e-02 4.46366019e-02\n",
      " 1.79570591e-02 5.09235303e-03 6.03660144e-04 4.77777798e-05\n",
      " 9.80392161e-07 4.77777789e-05 1.12281048e-03 8.01496744e-03\n",
      " 3.42098697e-02 8.52332035e-02 1.44443792e-01 1.99917910e-01\n",
      " 2.44510394e-01 2.79496146e-01 3.05412944e-01 3.24057519e-01\n",
      " 3.52813467e-01 3.97671833e-01 4.40962683e-01 4.61974317e-01\n",
      " 4.54606344e-01 4.21303925e-01 3.61872094e-01 2.81895297e-01\n",
      " 1.99216669e-01 1.28211635e-01 7.36194779e-02 3.59072554e-02\n",
      " 1.42747061e-02 4.19019615e-03 5.75294129e-04 2.67973863e-05\n",
      " 0.00000000e+00 5.98692833e-05 1.30196081e-03 8.84575176e-03\n",
      " 3.33845102e-02 8.11532688e-02 1.45432224e-01 2.10956995e-01\n",
      " 2.70076473e-01 3.18272944e-01 3.54533009e-01 3.83867846e-01\n",
      " 4.18566931e-01 4.60154971e-01 4.90009481e-01 4.92375494e-01\n",
      " 4.63593141e-01 4.07081703e-01 3.28926996e-01 2.40139806e-01\n",
      " 1.60598041e-01 9.78197396e-02 5.34455562e-02 2.56372553e-02\n",
      " 1.06426799e-02 2.93790855e-03 4.37973865e-04 6.60130729e-06\n",
      " 2.09150339e-06 4.98039234e-05 1.11464054e-03 7.21254913e-03\n",
      " 2.60101311e-02 6.62764060e-02 1.28664576e-01 2.02238760e-01\n",
      " 2.76171505e-01 3.42164708e-01 3.96020134e-01 4.41002945e-01\n",
      " 4.80760788e-01 5.11263925e-01 5.17038827e-01 4.89678566e-01\n",
      " 4.31473729e-01 3.50847062e-01 2.61142225e-01 1.78813270e-01\n",
      " 1.11986929e-01 6.39051642e-02 3.33783664e-02 1.61140525e-02\n",
      " 6.67836612e-03 1.74045755e-03 2.31568634e-04 2.54901970e-06\n",
      " 2.02614379e-06 3.85620929e-06 7.33660146e-04 4.26653602e-03\n",
      " 1.54683663e-02 4.25308502e-02 9.17279749e-02 1.59366799e-01\n",
      " 2.39094839e-01 3.17668238e-01 3.88672290e-01 4.43531376e-01\n",
      " 4.80487520e-01 4.91381376e-01 4.72994383e-01 4.20336735e-01\n",
      " 3.43946735e-01 2.58717846e-01 1.77779283e-01 1.12669871e-01\n",
      " 6.62880400e-02 3.59272554e-02 1.84665362e-02 8.72555569e-03\n",
      " 3.27503274e-03 7.41634006e-04 6.99346427e-05 4.70588257e-06\n",
      " 0.00000000e+00 0.00000000e+00 2.51633994e-04 1.64222226e-03\n",
      " 6.79490207e-03 1.96656212e-02 4.71800660e-02 9.38828770e-02\n",
      " 1.57868956e-01 2.30950917e-01 3.03015166e-01 3.60910591e-01\n",
      " 3.90997585e-01 3.88881049e-01 3.55263140e-01 2.96405885e-01\n",
      " 2.25827976e-01 1.57622747e-01 9.99891515e-02 5.97640530e-02\n",
      " 3.34262096e-02 1.73303270e-02 8.64732039e-03 3.84960791e-03\n",
      " 1.21712421e-03 2.27320267e-04 3.77124197e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.21568636e-05 4.79215698e-04\n",
      " 2.13189547e-03 6.27784324e-03 1.64835950e-02 3.58571900e-02\n",
      " 6.59906544e-02 1.06183596e-01 1.49425034e-01 1.84485427e-01\n",
      " 2.02387257e-01 1.99851963e-01 1.78186603e-01 1.44096211e-01\n",
      " 1.07614838e-01 7.49356219e-02 4.75064712e-02 2.82937258e-02\n",
      " 1.55267976e-02 7.81640533e-03 3.73032685e-03 1.56718957e-03\n",
      " 3.99281052e-04 8.69934654e-05 7.58169952e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.14379110e-06 6.97385633e-05\n",
      " 5.01111120e-04 1.86078434e-03 5.51176479e-03 1.24736603e-02\n",
      " 2.40917650e-02 3.85439220e-02 5.43895431e-02 6.55620922e-02\n",
      " 7.09804583e-02 6.97074517e-02 6.19908504e-02 5.14649026e-02\n",
      " 4.11688240e-02 3.05535952e-02 2.04781702e-02 1.24005230e-02\n",
      " 6.63267982e-03 3.23679743e-03 1.45326800e-03 5.48300663e-04\n",
      " 1.22614382e-04 1.39869283e-05 6.79738571e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.48366023e-06\n",
      " 1.39019610e-04 6.39542495e-04 2.11091506e-03 4.70333340e-03\n",
      " 9.08267985e-03 1.37703270e-02 1.90204578e-02 2.34518957e-02\n",
      " 2.52737912e-02 2.45460134e-02 2.18451637e-02 1.74539872e-02\n",
      " 1.38624838e-02 1.01639871e-02 6.67124192e-03 3.95529418e-03\n",
      " 2.11875820e-03 9.34901976e-04 2.95163404e-04 6.33986951e-05\n",
      " 2.02614381e-06 3.85620917e-06 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 9.93464071e-06 6.11111122e-05 1.63267978e-04 3.49803927e-04\n",
      " 5.02810465e-04 7.71503279e-04 1.31771244e-03 1.68614382e-03\n",
      " 2.06267977e-03 2.31640527e-03 2.69816997e-03 2.32183010e-03\n",
      " 1.89307193e-03 1.34712420e-03 7.86013083e-04 3.48496737e-04\n",
      " 1.78954252e-04 7.56209172e-05 5.92810466e-05 7.84313728e-06\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "[1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.86399931e-03 5.33795270e-03 3.45807430e-03 1.44086439e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 2.56153683e-04 7.63271603e-04 4.13726510e-03 8.21606246e-03\n",
      " 1.16158375e-02 1.30347136e-02 1.90951274e-02 2.16823027e-02\n",
      " 2.23279684e-02 2.23275803e-02 2.32275215e-02 2.26120478e-02\n",
      " 2.34131845e-02 2.12289265e-02 1.69821855e-02 1.45746258e-02\n",
      " 1.25829934e-02 7.61987131e-03 4.74992755e-03 3.16301738e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.02461473e-03 5.08790015e-04\n",
      " 3.19802684e-03 1.79417632e-03 1.04628610e-02 1.95859794e-02\n",
      " 2.79851558e-02 3.80955561e-02 5.07071665e-02 6.09411034e-02\n",
      " 7.38051698e-02 8.61348942e-02 9.72279334e-02 1.02734031e-01\n",
      " 1.05095277e-01 1.00908457e-01 9.12724354e-02 7.86841409e-02\n",
      " 5.99731410e-02 4.35843652e-02 2.92865792e-02 1.55325400e-02\n",
      " 9.80275291e-03 4.32344510e-03 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.36193124e-03 2.58620178e-03\n",
      " 3.34907240e-03 1.23536880e-02 2.36411627e-02 3.89208536e-02\n",
      " 5.72357204e-02 8.07234889e-02 1.04053941e-01 1.27616730e-01\n",
      " 1.48193662e-01 1.69389360e-01 1.87408821e-01 1.98045340e-01\n",
      " 1.96000352e-01 1.86913102e-01 1.68626485e-01 1.43762189e-01\n",
      " 1.11390353e-01 8.24682963e-02 5.41700375e-02 3.44101747e-02\n",
      " 2.10456792e-02 7.14435735e-03 2.07815580e-03 1.00000000e+00\n",
      " 1.00000000e+00 6.08364933e-04 2.63511567e-03 3.77852339e-03\n",
      " 1.32367751e-02 3.19559826e-02 5.19390970e-02 8.16600094e-02\n",
      " 1.16147068e-01 1.55307733e-01 1.95569030e-01 2.34530939e-01\n",
      " 2.71693796e-01 3.05450449e-01 3.28558736e-01 3.39036242e-01\n",
      " 3.35918531e-01 3.19183005e-01 2.90384415e-01 2.51997762e-01\n",
      " 2.05020102e-01 1.56644517e-01 1.12507388e-01 7.70371812e-02\n",
      " 4.77129272e-02 2.09148422e-02 8.15824925e-03 1.38183156e-03\n",
      " 1.00000000e+00 1.00000000e+00 3.39929407e-03 1.12666494e-02\n",
      " 2.99171930e-02 6.33007120e-02 1.00737670e-01 1.43820143e-01\n",
      " 1.93080433e-01 2.44203363e-01 2.92356285e-01 3.36351165e-01\n",
      " 3.74971182e-01 4.04238538e-01 4.20258915e-01 4.25475825e-01\n",
      " 4.23110051e-01 4.12192048e-01 3.87961292e-01 3.51046826e-01\n",
      " 3.00919326e-01 2.42655255e-01 1.86280131e-01 1.36809903e-01\n",
      " 8.95341181e-02 4.42040351e-02 1.73950084e-02 2.24528649e-03\n",
      " 1.00000000e+00 1.29072625e-04 6.88568774e-03 2.38787360e-02\n",
      " 5.55558373e-02 9.67938895e-02 1.46432185e-01 2.02954658e-01\n",
      " 2.60524304e-01 3.15775473e-01 3.62350920e-01 3.97950690e-01\n",
      " 4.22445396e-01 4.35367681e-01 4.39888230e-01 4.40528057e-01\n",
      " 4.40513154e-01 4.39807469e-01 4.30860919e-01 4.06821055e-01\n",
      " 3.64981249e-01 3.06264840e-01 2.42603870e-01 1.80260398e-01\n",
      " 1.22172625e-01 6.98991475e-02 3.02491845e-02 8.07882658e-03\n",
      " 7.52451388e-04 5.84880732e-03 1.60884432e-02 3.94850908e-02\n",
      " 8.02464236e-02 1.30295155e-01 1.89022927e-01 2.50907134e-01\n",
      " 3.10026210e-01 3.61838473e-01 3.99023010e-01 4.21442602e-01\n",
      " 4.31183845e-01 4.32970645e-01 4.33063577e-01 4.31849595e-01\n",
      " 4.32253987e-01 4.34012211e-01 4.35216443e-01 4.26007362e-01\n",
      " 3.96302368e-01 3.44638607e-01 2.77622970e-01 2.07215292e-01\n",
      " 1.40010271e-01 8.35571302e-02 3.54199286e-02 8.12392815e-03\n",
      " 3.17336281e-03 1.15054896e-02 2.99818440e-02 6.05999467e-02\n",
      " 1.05397491e-01 1.57757846e-01 2.19832361e-01 2.84982813e-01\n",
      " 3.45362693e-01 3.92410713e-01 4.20532903e-01 4.32999200e-01\n",
      " 4.35720823e-01 4.36738151e-01 4.36025746e-01 4.34514752e-01\n",
      " 4.34371468e-01 4.35370478e-01 4.36799248e-01 4.32158433e-01\n",
      " 4.10188756e-01 3.63291718e-01 2.94444312e-01 2.15119144e-01\n",
      " 1.42544567e-01 8.47008883e-02 3.50151124e-02 7.89315257e-03\n",
      " 3.23161133e-03 1.47626197e-02 3.78929050e-02 7.24407947e-02\n",
      " 1.15922352e-01 1.70021714e-01 2.36599869e-01 3.06047161e-01\n",
      " 3.67161754e-01 4.09342310e-01 4.31325822e-01 4.37054307e-01\n",
      " 4.36605391e-01 4.31795400e-01 4.27350003e-01 4.26461358e-01\n",
      " 4.28741267e-01 4.33493046e-01 4.35824819e-01 4.31289756e-01\n",
      " 4.10109126e-01 3.64152803e-01 2.93515879e-01 2.08025086e-01\n",
      " 1.28811388e-01 7.09264586e-02 2.92235942e-02 7.83063119e-03\n",
      " 4.52878453e-03 1.70789686e-02 3.88444657e-02 7.12210403e-02\n",
      " 1.14070807e-01 1.70407999e-01 2.42296874e-01 3.15194639e-01\n",
      " 3.78294423e-01 4.17010170e-01 4.32766435e-01 4.34394826e-01\n",
      " 4.23429401e-01 4.08131581e-01 4.03755779e-01 4.12502632e-01\n",
      " 4.21210143e-01 4.30359736e-01 4.33193544e-01 4.27920032e-01\n",
      " 4.01755748e-01 3.52587692e-01 2.81470030e-01 1.95168025e-01\n",
      " 1.13235444e-01 5.55043605e-02 2.35430108e-02 6.18728057e-03\n",
      " 3.29800169e-03 1.44242111e-02 3.49660668e-02 6.12294020e-02\n",
      " 1.04020430e-01 1.66382224e-01 2.44836898e-01 3.23629947e-01\n",
      " 3.87682912e-01 4.22322120e-01 4.32115928e-01 4.26741236e-01\n",
      " 4.08073044e-01 3.92631136e-01 4.03006780e-01 4.17598824e-01\n",
      " 4.23339759e-01 4.31104063e-01 4.33010695e-01 4.23244122e-01\n",
      " 3.88244587e-01 3.33733269e-01 2.68896216e-01 1.90874189e-01\n",
      " 1.04522710e-01 3.87934279e-02 1.74297739e-02 3.50967618e-03\n",
      " 2.80938436e-03 1.05495119e-02 2.60908874e-02 5.02513687e-02\n",
      " 9.44867883e-02 1.66603499e-01 2.53619217e-01 3.36658861e-01\n",
      " 3.98080742e-01 4.27343687e-01 4.31913093e-01 4.24262734e-01\n",
      " 4.07777433e-01 4.04115179e-01 4.27074463e-01 4.34660156e-01\n",
      " 4.30752599e-01 4.35709630e-01 4.36256166e-01 4.17188551e-01\n",
      " 3.72523437e-01 3.19211667e-01 2.62147667e-01 1.95183638e-01\n",
      " 1.09488574e-01 3.31381010e-02 1.45483953e-02 4.01827811e-03\n",
      " 5.12307366e-04 6.54528124e-03 1.88237811e-02 4.17306961e-02\n",
      " 9.17880503e-02 1.74855067e-01 2.68475805e-01 3.50009728e-01\n",
      " 4.05689597e-01 4.29284724e-01 4.31730136e-01 4.24779952e-01\n",
      " 4.17066408e-01 4.26337845e-01 4.46325716e-01 4.37669661e-01\n",
      " 4.31164133e-01 4.39797506e-01 4.37449699e-01 4.10561293e-01\n",
      " 3.64325447e-01 3.16548399e-01 2.64446789e-01 2.03016769e-01\n",
      " 1.21641789e-01 3.85283886e-02 1.39256905e-02 5.75533712e-03\n",
      " 1.80908516e-03 4.05001779e-03 1.16098077e-02 3.56094672e-02\n",
      " 9.29434125e-02 1.88086665e-01 2.83219151e-01 3.59855155e-01\n",
      " 4.08891075e-01 4.29016446e-01 4.29624440e-01 4.25024753e-01\n",
      " 4.24367029e-01 4.37451504e-01 4.45989038e-01 4.29497447e-01\n",
      " 4.30742139e-01 4.40698386e-01 4.35579303e-01 4.08875040e-01\n",
      " 3.68469968e-01 3.23541194e-01 2.71864744e-01 2.09708448e-01\n",
      " 1.29407796e-01 4.66599345e-02 1.47110594e-02 1.24451437e-03\n",
      " 6.02861274e-04 3.61944383e-03 9.48414401e-03 3.72179596e-02\n",
      " 9.94370858e-02 2.03847407e-01 2.94808732e-01 3.62492522e-01\n",
      " 4.04850219e-01 4.24188649e-01 4.25632029e-01 4.24916306e-01\n",
      " 4.29711912e-01 4.41598174e-01 4.41628199e-01 4.28732089e-01\n",
      " 4.36689350e-01 4.41619806e-01 4.30760466e-01 4.08474859e-01\n",
      " 3.74819936e-01 3.32341151e-01 2.77777040e-01 2.09826606e-01\n",
      " 1.30239964e-01 5.49630900e-02 1.96191137e-02 4.66328644e-03\n",
      " 6.40384192e-04 2.31920571e-03 1.34946268e-02 4.02421250e-02\n",
      " 1.11635534e-01 2.18127567e-01 3.02307089e-01 3.58900705e-01\n",
      " 3.94546859e-01 4.12055475e-01 4.16376789e-01 4.20613745e-01\n",
      " 4.31374877e-01 4.42848353e-01 4.41739404e-01 4.36405933e-01\n",
      " 4.39787241e-01 4.36199004e-01 4.25533823e-01 4.07959653e-01\n",
      " 3.79704398e-01 3.34355741e-01 2.75929953e-01 2.04211177e-01\n",
      " 1.26897985e-01 6.00528521e-02 2.19826328e-02 5.39565973e-03\n",
      " 1.00000000e+00 3.19769484e-03 1.73243603e-02 5.05902373e-02\n",
      " 1.31238536e-01 2.31807745e-01 3.05774320e-01 3.53075626e-01\n",
      " 3.81937845e-01 3.97608842e-01 4.04810491e-01 4.13572984e-01\n",
      " 4.25805853e-01 4.34859477e-01 4.38885854e-01 4.38310592e-01\n",
      " 4.35527568e-01 4.30787832e-01 4.24612599e-01 4.09263253e-01\n",
      " 3.79380122e-01 3.29857721e-01 2.65770526e-01 1.93006356e-01\n",
      " 1.20131328e-01 6.27444100e-02 2.29200460e-02 3.25247040e-03\n",
      " 1.26160216e-03 3.28232035e-03 2.12436551e-02 6.52908567e-02\n",
      " 1.50109665e-01 2.44140307e-01 3.11860255e-01 3.53540641e-01\n",
      " 3.77155641e-01 3.92477753e-01 4.03181195e-01 4.11168121e-01\n",
      " 4.17307271e-01 4.27972311e-01 4.35984607e-01 4.35111888e-01\n",
      " 4.32143168e-01 4.32172247e-01 4.27531348e-01 4.10344209e-01\n",
      " 3.73765722e-01 3.19549378e-01 2.53514376e-01 1.81534651e-01\n",
      " 1.13507923e-01 5.96029291e-02 1.91286162e-02 4.89505647e-03\n",
      " 2.40144059e-04 4.23499444e-03 2.82417581e-02 7.71765731e-02\n",
      " 1.61381798e-01 2.52559367e-01 3.19776782e-01 3.62083798e-01\n",
      " 3.86953039e-01 4.03182791e-01 4.13622949e-01 4.20454888e-01\n",
      " 4.25707567e-01 4.32593973e-01 4.37113421e-01 4.35484540e-01\n",
      " 4.33733467e-01 4.35656533e-01 4.27490991e-01 4.02005357e-01\n",
      " 3.58699700e-01 3.00208990e-01 2.32377026e-01 1.62707587e-01\n",
      " 1.01197949e-01 5.36029194e-02 1.97136151e-02 3.33891116e-03\n",
      " 1.00000000e+00 5.78888787e-03 3.00867078e-02 8.10295301e-02\n",
      " 1.59709610e-01 2.45751704e-01 3.19718903e-01 3.70622237e-01\n",
      " 4.01335976e-01 4.18449158e-01 4.27788603e-01 4.33011048e-01\n",
      " 4.36079713e-01 4.37665968e-01 4.37155294e-01 4.36138315e-01\n",
      " 4.36224685e-01 4.33373183e-01 4.17765952e-01 3.83003631e-01\n",
      " 3.29052015e-01 2.65129246e-01 1.98466757e-01 1.36941913e-01\n",
      " 8.75022949e-02 4.41831818e-02 1.68237933e-02 1.14341696e-03\n",
      " 5.12307366e-04 4.97566354e-03 2.75228500e-02 7.21365245e-02\n",
      " 1.38203464e-01 2.21193185e-01 3.01146967e-01 3.64229204e-01\n",
      " 4.05075770e-01 4.26858829e-01 4.35830249e-01 4.37093034e-01\n",
      " 4.35620521e-01 4.32785887e-01 4.33689851e-01 4.35151839e-01\n",
      " 4.33769249e-01 4.21573248e-01 3.91443625e-01 3.42099005e-01\n",
      " 2.80622974e-01 2.15385994e-01 1.56981420e-01 1.08370593e-01\n",
      " 6.89232265e-02 3.41727928e-02 1.14556108e-02 6.24374566e-04\n",
      " 4.96297714e-04 6.42176487e-04 2.17662308e-02 5.40256238e-02\n",
      " 1.04698945e-01 1.74844016e-01 2.54555062e-01 3.27616482e-01\n",
      " 3.84143636e-01 4.19805043e-01 4.37331295e-01 4.42570717e-01\n",
      " 4.40979068e-01 4.39739270e-01 4.40060330e-01 4.36453825e-01\n",
      " 4.20643406e-01 3.89250803e-01 3.39535825e-01 2.80174316e-01\n",
      " 2.18722481e-01 1.62067481e-01 1.15875053e-01 7.92794836e-02\n",
      " 4.67596188e-02 1.99709585e-02 5.73168546e-03 1.15269151e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.10663184e-02 3.16387566e-02\n",
      " 6.79571571e-02 1.16757300e-01 1.81245192e-01 2.53849283e-01\n",
      " 3.22117111e-01 3.75303744e-01 4.10046262e-01 4.28037126e-01\n",
      " 4.33501826e-01 4.32183179e-01 4.23058943e-01 4.03462389e-01\n",
      " 3.68653162e-01 3.20325083e-01 2.63179088e-01 2.06926784e-01\n",
      " 1.56606364e-01 1.12777879e-01 7.92416076e-02 5.19523948e-02\n",
      " 2.80979521e-02 1.17515874e-02 3.62532902e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 6.00392720e-03 1.66683125e-02\n",
      " 3.70324077e-02 6.58672516e-02 1.07308251e-01 1.60489048e-01\n",
      " 2.17376444e-01 2.73330940e-01 3.17793193e-01 3.46046274e-01\n",
      " 3.57255277e-01 3.55113288e-01 3.38009365e-01 3.07860131e-01\n",
      " 2.71888499e-01 2.30720619e-01 1.85786222e-01 1.45385523e-01\n",
      " 1.07396738e-01 7.68019355e-02 5.22270257e-02 3.28016565e-02\n",
      " 1.55045932e-02 7.64480388e-03 1.59518179e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.21895805e-04 6.36056247e-03\n",
      " 1.81532724e-02 3.60941674e-02 6.35201977e-02 9.71529167e-02\n",
      " 1.37059545e-01 1.72800513e-01 2.03980969e-01 2.22361735e-01\n",
      " 2.30826686e-01 2.28414128e-01 2.14329317e-01 1.95512097e-01\n",
      " 1.76143215e-01 1.51986898e-01 1.25102561e-01 9.71325451e-02\n",
      " 7.05866005e-02 4.92788812e-02 3.16433211e-02 1.90920398e-02\n",
      " 7.81329879e-03 2.46452407e-03 1.66499879e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 6.08364933e-04\n",
      " 9.19357123e-03 2.03873626e-02 3.95819575e-02 5.93643343e-02\n",
      " 8.38066119e-02 1.02779687e-01 1.20754707e-01 1.33930077e-01\n",
      " 1.38390298e-01 1.35962370e-01 1.28594389e-01 1.13961175e-01\n",
      " 1.02356670e-01 8.72592822e-02 7.10074801e-02 5.44979849e-02\n",
      " 4.04618367e-02 2.56961215e-02 1.37265743e-02 4.86960099e-03\n",
      " 4.50833726e-04 9.44566601e-04 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.71577897e-03 6.74974073e-03 1.02007785e-02 1.58140920e-02\n",
      " 1.87294394e-02 2.42267775e-02 3.01202361e-02 3.56607164e-02\n",
      " 3.88168267e-02 4.09093942e-02 4.47173259e-02 4.12439828e-02\n",
      " 3.68541869e-02 3.15986901e-02 2.36957717e-02 1.55143368e-02\n",
      " 1.11365541e-02 6.61472829e-03 6.58144848e-03 1.35920311e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# standard scores for the columns... along axis 0\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X_train1))\n",
    "# show standardization constants being employed\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)\n",
    "\n",
    "# the model data will be standardized form of preliminary model data\n",
    "X_train = scaler.fit_transform(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.49019614e-05 9.25490201e-05 6.19607866e-05\n",
      " 1.58039218e-04 2.00392162e-04 4.10588240e-04 9.18823545e-04\n",
      " 1.21098041e-03 1.04313728e-03 1.20823531e-03 9.18823544e-04\n",
      " 2.70980397e-04 3.51764712e-04 3.68627456e-04 1.96862746e-04\n",
      " 7.52941206e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.71372555e-04 4.37254908e-04 5.69803935e-04\n",
      " 1.14705885e-03 2.38117650e-03 4.76705890e-03 8.42039227e-03\n",
      " 1.10454904e-02 1.30737257e-02 1.51149022e-02 1.51145100e-02\n",
      " 1.36827453e-02 1.08360786e-02 8.29176482e-03 6.02431379e-03\n",
      " 3.96196084e-03 1.78470591e-03 8.92941187e-04 3.09411770e-04\n",
      " 1.96078438e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.00000042e-05 2.87058831e-04 1.01686276e-03 2.22549024e-03\n",
      " 5.04509813e-03 1.01874511e-02 1.81803924e-02 2.70568631e-02\n",
      " 3.67831377e-02 4.49466672e-02 4.94517653e-02 5.17168633e-02\n",
      " 4.73054908e-02 3.88305887e-02 3.07686278e-02 2.17478434e-02\n",
      " 1.34960786e-02 7.13411774e-03 4.13647064e-03 1.68823532e-03\n",
      " 5.21568635e-04 1.76862746e-04 6.39215708e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.37254911e-05\n",
      " 4.01960793e-04 8.45882367e-04 3.83607851e-03 9.91647075e-03\n",
      " 1.97611768e-02 3.70333339e-02 6.03168635e-02 9.03635305e-02\n",
      " 1.21621570e-01 1.52694119e-01 1.79341178e-01 1.88115296e-01\n",
      " 1.75710982e-01 1.48223531e-01 1.11967844e-01 8.11705892e-02\n",
      " 5.33717654e-02 3.10592161e-02 1.72247062e-02 8.31137270e-03\n",
      " 3.11764712e-03 7.89411777e-04 3.23921574e-04 0.00000000e+00\n",
      " 0.00000000e+00 9.41176489e-06 5.49019617e-06 1.39215690e-04\n",
      " 1.87411769e-03 5.61333343e-03 1.42843139e-02 2.86129416e-02\n",
      " 5.15545104e-02 8.84839226e-02 1.37799217e-01 1.94270198e-01\n",
      " 2.50277649e-01 3.05923140e-01 3.48592160e-01 3.66041572e-01\n",
      " 3.53688630e-01 3.14914905e-01 2.53966277e-01 1.89460002e-01\n",
      " 1.30453727e-01 8.01639225e-02 4.72423536e-02 2.43172553e-02\n",
      " 1.11521571e-02 3.00431380e-03 8.92156881e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.52941179e-05 1.00039218e-03\n",
      " 5.31490204e-03 1.32560786e-02 2.81619611e-02 5.52921575e-02\n",
      " 9.65513737e-02 1.54664315e-01 2.23466669e-01 2.98192160e-01\n",
      " 3.70335689e-01 4.32479219e-01 4.80089415e-01 4.99175298e-01\n",
      " 4.81098043e-01 4.38811376e-01 3.73025101e-01 2.89016865e-01\n",
      " 2.06107453e-01 1.31271766e-01 7.71501970e-02 4.01937260e-02\n",
      " 2.06086277e-02 6.75294129e-03 1.58666669e-03 1.47843142e-04\n",
      " 0.00000000e+00 6.00000031e-05 4.56078442e-04 2.86980397e-03\n",
      " 1.04239217e-02 2.35737258e-02 4.64886281e-02 8.69247069e-02\n",
      " 1.47081178e-01 2.23834904e-01 3.07879611e-01 3.91978827e-01\n",
      " 4.56543925e-01 5.01888239e-01 5.29712945e-01 5.35808239e-01\n",
      " 5.23263141e-01 4.96409023e-01 4.44052945e-01 3.64656474e-01\n",
      " 2.65396081e-01 1.74192943e-01 1.00415687e-01 5.38266674e-02\n",
      " 2.59580396e-02 9.95450997e-03 2.06235298e-03 1.11764711e-04\n",
      " 0.00000000e+00 2.57254907e-04 1.39176473e-03 4.72941185e-03\n",
      " 1.45850982e-02 3.22619612e-02 6.22996086e-02 1.13750590e-01\n",
      " 1.93691375e-01 2.89005885e-01 3.84451768e-01 4.49483141e-01\n",
      " 4.78444317e-01 4.84190984e-01 4.83457258e-01 4.79956082e-01\n",
      " 4.82730984e-01 4.86161572e-01 4.60894513e-01 3.94298042e-01\n",
      " 2.94285101e-01 1.93954119e-01 1.12998825e-01 5.79854909e-02\n",
      " 2.73235298e-02 1.10176472e-02 2.85647065e-03 1.81176474e-04\n",
      " 6.23529442e-05 6.17254917e-04 1.93019610e-03 6.51450989e-03\n",
      " 1.67305884e-02 3.61458828e-02 7.17247067e-02 1.32214511e-01\n",
      " 2.27485100e-01 3.38090983e-01 4.22680788e-01 4.50380788e-01\n",
      " 4.31235298e-01 3.99043140e-01 3.87089807e-01 3.89446670e-01\n",
      " 4.11964709e-01 4.45032945e-01 4.43772552e-01 3.87170983e-01\n",
      " 2.92764708e-01 1.93732159e-01 1.13616472e-01 5.61552947e-02\n",
      " 2.35937258e-02 8.00196093e-03 2.06666671e-03 2.16470593e-04\n",
      " 1.10980393e-04 4.56470593e-04 1.81450984e-03 5.79176479e-03\n",
      " 1.48600002e-02 3.42215690e-02 7.43772558e-02 1.44304315e-01\n",
      " 2.50533728e-01 3.61129807e-01 4.22584709e-01 4.11405886e-01\n",
      " 3.53958434e-01 3.14912160e-01 3.12942356e-01 3.31545493e-01\n",
      " 3.70519611e-01 4.22901572e-01 4.27222356e-01 3.67704709e-01\n",
      " 2.73241571e-01 1.78180786e-01 1.05595687e-01 5.13980398e-02\n",
      " 1.87611768e-02 4.30980400e-03 1.36980395e-03 2.59607847e-04\n",
      " 1.49019614e-05 2.44313731e-04 1.36705884e-03 4.00941182e-03\n",
      " 1.11623531e-02 3.29066671e-02 7.84505891e-02 1.60081962e-01\n",
      " 2.72611767e-01 3.73212552e-01 4.09867062e-01 3.70936474e-01\n",
      " 3.06222356e-01 2.81876866e-01 2.98589807e-01 3.40407062e-01\n",
      " 3.88404317e-01 4.33329023e-01 4.21568631e-01 3.46918434e-01\n",
      " 2.49108630e-01 1.60716864e-01 9.68090206e-02 4.92447063e-02\n",
      " 1.76047062e-02 2.65725496e-03 7.81960797e-04 7.92156890e-05\n",
      " 0.00000000e+00 1.73725493e-04 8.51764720e-04 2.48862749e-03\n",
      " 9.48509819e-03 3.45592162e-02 8.94160795e-02 1.79511766e-01\n",
      " 2.90823140e-01 3.73884317e-01 3.95278827e-01 3.51974121e-01\n",
      " 3.03504709e-01 3.08408630e-01 3.54049807e-01 4.07117258e-01\n",
      " 4.52305886e-01 4.71231768e-01 4.27438043e-01 3.29017258e-01\n",
      " 2.27258434e-01 1.47285099e-01 9.38815695e-02 5.09800005e-02\n",
      " 1.86270591e-02 2.29450986e-03 1.50980397e-04 0.00000000e+00\n",
      " 0.00000000e+00 7.21568651e-05 4.06666677e-04 1.78666670e-03\n",
      " 9.19058837e-03 4.01560790e-02 1.01809805e-01 1.94792159e-01\n",
      " 2.98222747e-01 3.67717650e-01 3.80408630e-01 3.50872552e-01\n",
      " 3.31036473e-01 3.77930984e-01 4.45905493e-01 4.99253337e-01\n",
      " 5.20803533e-01 5.05857651e-01 4.31335297e-01 3.17335689e-01\n",
      " 2.17505100e-01 1.46241962e-01 9.68121578e-02 5.43184319e-02\n",
      " 2.03039219e-02 2.43176474e-03 1.03921569e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.72549022e-04 1.33921570e-03\n",
      " 1.01145100e-02 4.71996084e-02 1.10416080e-01 2.01779217e-01\n",
      " 2.94900395e-01 3.56045885e-01 3.67435689e-01 3.59073729e-01\n",
      " 3.75494121e-01 4.56161180e-01 5.20294905e-01 5.59936474e-01\n",
      " 5.50515690e-01 5.09116474e-01 4.24576474e-01 3.09812160e-01\n",
      " 2.19285100e-01 1.54587060e-01 1.01425883e-01 5.90035300e-02\n",
      " 2.22470591e-02 3.15803928e-03 1.45882358e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.74901963e-04 1.33333336e-03\n",
      " 1.24976472e-02 5.35968634e-02 1.15214119e-01 1.97806668e-01\n",
      " 2.80458826e-01 3.34396865e-01 3.53387062e-01 3.64518042e-01\n",
      " 4.12314905e-01 4.92022748e-01 5.41753337e-01 5.60562357e-01\n",
      " 5.32821572e-01 4.88372944e-01 4.04570199e-01 3.08616473e-01\n",
      " 2.29561963e-01 1.65038825e-01 1.06238825e-01 5.97282359e-02\n",
      " 2.24160788e-02 3.88901969e-03 2.49019615e-04 2.62745112e-05\n",
      " 0.00000000e+00 1.84313729e-05 4.46274516e-04 1.88392161e-03\n",
      " 1.56086277e-02 5.95184321e-02 1.18048236e-01 1.89958433e-01\n",
      " 2.59725100e-01 3.04442355e-01 3.26198042e-01 3.46467062e-01\n",
      " 3.97525493e-01 4.61883925e-01 5.02334905e-01 5.09992553e-01\n",
      " 4.91715690e-01 4.55175690e-01 3.87072160e-01 3.13357257e-01\n",
      " 2.43416865e-01 1.69190198e-01 1.05274511e-01 5.45160790e-02\n",
      " 2.01839219e-02 4.13294125e-03 3.18823536e-04 8.23529430e-05\n",
      " 0.00000000e+00 0.00000000e+00 5.61568633e-04 3.20196083e-03\n",
      " 2.03807846e-02 6.59890204e-02 1.21864707e-01 1.82540786e-01\n",
      " 2.40299218e-01 2.79466277e-01 2.98454905e-01 3.16838826e-01\n",
      " 3.53836866e-01 4.03531376e-01 4.42802356e-01 4.60054121e-01\n",
      " 4.58005494e-01 4.38408631e-01 3.86596082e-01 3.23680395e-01\n",
      " 2.47119218e-01 1.66043923e-01 9.87105893e-02 4.79819614e-02\n",
      " 1.73650983e-02 3.85294125e-03 2.30196086e-04 9.41176478e-05\n",
      " 0.00000000e+00 4.94117647e-05 8.13725510e-04 5.59647067e-03\n",
      " 2.58337258e-02 7.28678439e-02 1.30116080e-01 1.87514511e-01\n",
      " 2.35024708e-01 2.65842355e-01 2.86669022e-01 3.04618434e-01\n",
      " 3.27970983e-01 3.73289022e-01 4.19621964e-01 4.51620396e-01\n",
      " 4.60003141e-01 4.42189415e-01 3.95486670e-01 3.27743532e-01\n",
      " 2.37829414e-01 1.52318433e-01 8.58525500e-02 3.96831378e-02\n",
      " 1.44937257e-02 4.18274517e-03 5.97647072e-04 3.96078438e-05\n",
      " 0.00000000e+00 1.00000000e-04 8.50196087e-04 7.74980402e-03\n",
      " 2.96600003e-02 7.79909812e-02 1.38738041e-01 1.98550982e-01\n",
      " 2.49570982e-01 2.86431375e-01 3.15130198e-01 3.34353728e-01\n",
      " 3.55336866e-01 3.98058827e-01 4.49429023e-01 4.78263533e-01\n",
      " 4.83295298e-01 4.50781572e-01 3.91829807e-01 3.05878826e-01\n",
      " 2.10780394e-01 1.28520394e-01 6.95254911e-02 3.18423534e-02\n",
      " 1.24925492e-02 3.84274516e-03 4.84705892e-04 7.84313753e-06\n",
      " 0.00000000e+00 1.41176477e-05 1.04588237e-03 8.41725503e-03\n",
      " 2.89513729e-02 7.40458832e-02 1.37380393e-01 2.05374119e-01\n",
      " 2.68100002e-01 3.21151375e-01 3.64622748e-01 3.94023140e-01\n",
      " 4.23313336e-01 4.63550200e-01 5.05343141e-01 5.16521572e-01\n",
      " 4.94554121e-01 4.36237650e-01 3.51450199e-01 2.53778042e-01\n",
      " 1.63590198e-01 9.44486286e-02 4.92156869e-02 2.24568631e-02\n",
      " 9.03921582e-03 2.55137260e-03 3.49803928e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.01921571e-03 7.41764714e-03\n",
      " 2.37541180e-02 6.09309811e-02 1.20161962e-01 1.94560002e-01\n",
      " 2.70001179e-01 3.41900395e-01 4.02765885e-01 4.50051376e-01\n",
      " 4.86902357e-01 5.23016475e-01 5.41067063e-01 5.18755690e-01\n",
      " 4.59187455e-01 3.72956474e-01 2.72463140e-01 1.79108237e-01\n",
      " 1.07560785e-01 5.77556870e-02 2.85956867e-02 1.38717649e-02\n",
      " 5.49372557e-03 1.02627453e-03 2.05490199e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 4.00784323e-04 4.19803929e-03\n",
      " 1.41250983e-02 3.94105888e-02 8.34984324e-02 1.50045492e-01\n",
      " 2.30135688e-01 3.14210591e-01 3.87734905e-01 4.45869807e-01\n",
      " 4.81974121e-01 5.03455690e-01 4.97469415e-01 4.46277650e-01\n",
      " 3.66450984e-01 2.69000003e-01 1.81724316e-01 1.09135688e-01\n",
      " 5.92443146e-02 2.99298043e-02 1.44635296e-02 6.80627460e-03\n",
      " 2.80156867e-03 7.65882364e-04 6.58823557e-05 0.00000000e+00\n",
      " 0.00000000e+00 9.41176489e-06 1.27450984e-04 1.41372551e-03\n",
      " 5.83254913e-03 1.77752944e-02 4.17050986e-02 8.59490208e-02\n",
      " 1.48864315e-01 2.20709414e-01 2.95741571e-01 3.55968238e-01\n",
      " 3.94602356e-01 4.00620788e-01 3.76465101e-01 3.18418434e-01\n",
      " 2.41617257e-01 1.64696865e-01 1.02727060e-01 5.53752949e-02\n",
      " 2.85066671e-02 1.35490198e-02 6.53372559e-03 2.86156867e-03\n",
      " 8.11764727e-04 3.35294122e-04 3.92156886e-07 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.40784324e-04\n",
      " 1.67058827e-03 5.34196087e-03 1.32819610e-02 3.06800005e-02\n",
      " 6.02674518e-02 9.63952952e-02 1.37094904e-01 1.70709022e-01\n",
      " 1.95856081e-01 2.01347061e-01 1.89610982e-01 1.59618041e-01\n",
      " 1.20678825e-01 8.04811775e-02 4.71356869e-02 2.58564709e-02\n",
      " 1.34521571e-02 5.32549028e-03 2.25647063e-03 7.74901974e-04\n",
      " 1.12941179e-04 1.56862754e-06 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.41176473e-05\n",
      " 5.18823544e-04 1.66000003e-03 4.47333339e-03 1.07211766e-02\n",
      " 2.14552944e-02 3.49145102e-02 4.81145103e-02 6.21317654e-02\n",
      " 7.07752949e-02 7.34113734e-02 7.00945106e-02 5.91313733e-02\n",
      " 4.57101966e-02 3.12886279e-02 1.79976473e-02 1.03215688e-02\n",
      " 5.52823537e-03 2.40274512e-03 1.02941177e-03 3.51372554e-04\n",
      " 8.94117662e-05 2.66666681e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.84313731e-05 4.94509816e-04 1.83333337e-03 4.12823535e-03\n",
      " 7.66745108e-03 1.18737257e-02 1.57164708e-02 2.07141179e-02\n",
      " 2.46050983e-02 2.57682356e-02 2.39556866e-02 1.90666669e-02\n",
      " 1.48945100e-02 1.03317649e-02 5.53058832e-03 3.51215692e-03\n",
      " 2.16078434e-03 1.13372551e-03 4.51372554e-04 1.96078435e-04\n",
      " 1.05882356e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.62745102e-06 1.70588240e-04\n",
      " 3.48235297e-04 5.22352948e-04 6.27450989e-04 7.22745111e-04\n",
      " 1.22470590e-03 1.77803924e-03 2.18941180e-03 2.25333337e-03\n",
      " 1.79686277e-03 1.07490199e-03 7.03137266e-04 6.41568637e-04\n",
      " 2.06274517e-04 2.35294122e-06 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "[1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.49012163e-03 9.25443914e-03 6.19576865e-03\n",
      " 1.13096821e-02 1.05851043e-02 1.77097522e-02 2.54713070e-02\n",
      " 3.08436404e-02 2.74314903e-02 3.09689662e-02 2.65520043e-02\n",
      " 1.05126755e-02 1.67719643e-02 1.69242668e-02 1.35781898e-02\n",
      " 6.33746803e-03 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.62326966e-03 1.88424204e-02 1.90784971e-02\n",
      " 2.76803159e-02 4.05988818e-02 5.86610987e-02 7.94398820e-02\n",
      " 9.07563457e-02 9.72332972e-02 1.08151878e-01 1.06769227e-01\n",
      " 1.01181937e-01 9.01153738e-02 7.93545579e-02 6.92414111e-02\n",
      " 5.52806534e-02 3.67304653e-02 2.75377490e-02 1.42634495e-02\n",
      " 1.96068625e-04 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 6.01700031e-03 1.27053029e-02 2.65013517e-02 3.72027378e-02\n",
      " 5.99170024e-02 8.60493363e-02 1.17850305e-01 1.43703526e-01\n",
      " 1.67345886e-01 1.85014194e-01 1.93913034e-01 1.99308538e-01\n",
      " 1.89673708e-01 1.71265755e-01 1.53521598e-01 1.30101050e-01\n",
      " 1.00479295e-01 7.44131160e-02 5.61589183e-02 3.34978569e-02\n",
      " 1.93328611e-02 1.04702695e-02 6.39183770e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 4.98833171e-03\n",
      " 1.60002854e-02 2.21884462e-02 4.87853738e-02 8.29180216e-02\n",
      " 1.19255498e-01 1.61848877e-01 2.08983495e-01 2.54910631e-01\n",
      " 2.88790885e-01 3.17951346e-01 3.40264097e-01 3.47841559e-01\n",
      " 3.37006177e-01 3.12413902e-01 2.77183368e-01 2.41168895e-01\n",
      " 1.96522701e-01 1.50285992e-01 1.11458168e-01 7.63514951e-02\n",
      " 4.60108787e-02 2.31956656e-02 1.50597306e-02 1.00000000e+00\n",
      " 1.00000000e+00 9.41129456e-04 5.11280504e-04 5.34922643e-03\n",
      " 3.28446574e-02 6.13895866e-02 9.98902983e-02 1.43779406e-01\n",
      " 1.93788886e-01 2.50377854e-01 3.06049447e-01 3.52195042e-01\n",
      " 3.86267174e-01 4.11645477e-01 4.26067110e-01 4.30094056e-01\n",
      " 4.25555765e-01 4.12319389e-01 3.84801591e-01 3.46028214e-01\n",
      " 2.96906150e-01 2.38884140e-01 1.85368409e-01 1.32206609e-01\n",
      " 8.79814936e-02 4.25252480e-02 2.29453472e-02 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.13985363e-03 2.56108830e-02\n",
      " 6.08129815e-02 9.95896302e-02 1.44767652e-01 2.01218740e-01\n",
      " 2.61029767e-01 3.20268793e-01 3.69186935e-01 4.05360925e-01\n",
      " 4.25913170e-01 4.37039854e-01 4.39914218e-01 4.41034013e-01\n",
      " 4.39726990e-01 4.40408542e-01 4.29365989e-01 4.02654488e-01\n",
      " 3.61180582e-01 2.99009624e-01 2.36013182e-01 1.70359675e-01\n",
      " 1.22891320e-01 6.78619159e-02 3.30974119e-02 7.87022685e-03\n",
      " 1.00000000e+00 5.11410127e-03 1.58209779e-02 4.43875971e-02\n",
      " 8.76278557e-02 1.32557619e-01 1.83960154e-01 2.48298780e-01\n",
      " 3.10973095e-01 3.66883151e-01 4.04701442e-01 4.23843802e-01\n",
      " 4.33673447e-01 4.34992139e-01 4.33682667e-01 4.32516557e-01\n",
      " 4.31302602e-01 4.34292787e-01 4.35267879e-01 4.25454456e-01\n",
      " 3.92187765e-01 3.37450289e-01 2.64748384e-01 1.98327787e-01\n",
      " 1.36668357e-01 8.29953220e-02 3.70699489e-02 7.66813397e-03\n",
      " 1.00000000e+00 1.24511483e-02 3.18360242e-02 5.84775944e-02\n",
      " 1.03817276e-01 1.55330178e-01 2.14129093e-01 2.80966478e-01\n",
      " 3.50480465e-01 4.01455326e-01 4.27157102e-01 4.38088021e-01\n",
      " 4.38812829e-01 4.39198047e-01 4.39931297e-01 4.35615078e-01\n",
      " 4.33688711e-01 4.36221489e-01 4.37485706e-01 4.32487466e-01\n",
      " 4.05857194e-01 3.52778838e-01 2.81790510e-01 2.04823554e-01\n",
      " 1.40241963e-01 8.95195989e-02 4.28817803e-02 1.12209402e-02\n",
      " 5.54017513e-03 2.10008790e-02 3.98268739e-02 6.99144343e-02\n",
      " 1.14059548e-01 1.65714665e-01 2.30017534e-01 3.00636678e-01\n",
      " 3.73030039e-01 4.19616260e-01 4.36844166e-01 4.40275945e-01\n",
      " 4.36054238e-01 4.30739045e-01 4.30294918e-01 4.25409405e-01\n",
      " 4.28184479e-01 4.35940948e-01 4.39347618e-01 4.32234815e-01\n",
      " 4.06148046e-01 3.54365899e-01 2.82752032e-01 2.04164513e-01\n",
      " 1.29840073e-01 7.43903948e-02 3.65108934e-02 1.14438288e-02\n",
      " 9.13961031e-03 1.87717638e-02 3.60950125e-02 6.52697549e-02\n",
      " 1.07055876e-01 1.60886693e-01 2.31179115e-01 3.12135041e-01\n",
      " 3.83993381e-01 4.27107229e-01 4.39616175e-01 4.34659359e-01\n",
      " 4.20281505e-01 4.05968941e-01 4.05732439e-01 4.11590309e-01\n",
      " 4.21252253e-01 4.33865085e-01 4.35020095e-01 4.27104235e-01\n",
      " 3.98344118e-01 3.43685566e-01 2.75228832e-01 1.95351720e-01\n",
      " 1.12697377e-01 5.38952224e-02 3.01050566e-02 1.32763596e-02\n",
      " 1.49012163e-03 1.31205740e-02 3.29422229e-02 5.54846801e-02\n",
      " 9.05750462e-02 1.55032668e-01 2.36789208e-01 3.25948809e-01\n",
      " 3.96408043e-01 4.32658688e-01 4.36435178e-01 4.26367958e-01\n",
      " 4.03897320e-01 3.90303856e-01 4.03594101e-01 4.20265679e-01\n",
      " 4.26261163e-01 4.33190382e-01 4.33663312e-01 4.21354096e-01\n",
      " 3.86503489e-01 3.29959296e-01 2.66576024e-01 1.94661900e-01\n",
      " 1.12023402e-01 4.07548659e-02 2.33223706e-02 6.37757520e-03\n",
      " 1.00000000e+00 1.16992540e-02 2.58345448e-02 4.13770075e-02\n",
      " 8.01421824e-02 1.57609116e-01 2.52308110e-01 3.43230286e-01\n",
      " 4.06357543e-01 4.33425699e-01 4.36655002e-01 4.23253227e-01\n",
      " 4.03965928e-01 4.04232745e-01 4.28695121e-01 4.37651177e-01\n",
      " 4.31889222e-01 4.37940649e-01 4.36305573e-01 4.15055493e-01\n",
      " 3.72088936e-01 3.17231822e-01 2.64524069e-01 1.99129629e-01\n",
      " 1.17574513e-01 3.69696336e-02 6.21518266e-03 1.00000000e+00\n",
      " 1.00000000e+00 6.12149374e-03 1.60971418e-02 3.55609595e-02\n",
      " 7.98703459e-02 1.70734873e-01 2.69672487e-01 3.55907499e-01\n",
      " 4.12439934e-01 4.33127765e-01 4.32824856e-01 4.24543855e-01\n",
      " 4.16138267e-01 4.27747944e-01 4.48229953e-01 4.40396074e-01\n",
      " 4.30873672e-01 4.41020412e-01 4.38803627e-01 4.10438017e-01\n",
      " 3.66804915e-01 3.16465622e-01 2.68809495e-01 2.05830870e-01\n",
      " 1.22095735e-01 4.27649498e-02 9.85586035e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.03715400e-02 3.16408821e-02\n",
      " 8.43356241e-02 1.86891702e-01 2.81733804e-01 3.62800624e-01\n",
      " 4.10810648e-01 4.29221217e-01 4.29976057e-01 4.24442197e-01\n",
      " 4.22261211e-01 4.39625470e-01 4.46767608e-01 4.30635382e-01\n",
      " 4.30867472e-01 4.44299454e-01 4.38369635e-01 4.07945742e-01\n",
      " 3.71301740e-01 3.25972759e-01 2.75023739e-01 2.15276846e-01\n",
      " 1.27662368e-01 4.53618196e-02 8.10315719e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.03731319e-02 2.95188637e-02\n",
      " 9.49175460e-02 2.00108565e-01 2.88824651e-01 3.60827825e-01\n",
      " 4.06416711e-01 4.23381735e-01 4.24948812e-01 4.23211316e-01\n",
      " 4.30924074e-01 4.43117496e-01 4.41371834e-01 4.27889077e-01\n",
      " 4.37230554e-01 4.44420467e-01 4.31774345e-01 4.08882356e-01\n",
      " 3.76949386e-01 3.35132871e-01 2.79206364e-01 2.13863382e-01\n",
      " 1.28839876e-01 5.06887637e-02 1.27134256e-02 2.62731961e-03\n",
      " 1.00000000e+00 1.84304513e-03 1.79820281e-02 3.41120159e-02\n",
      " 1.05290462e-01 2.10162212e-01 2.93497180e-01 3.55329447e-01\n",
      " 3.95917612e-01 4.12476681e-01 4.17315818e-01 4.20153317e-01\n",
      " 4.32645743e-01 4.43784413e-01 4.43009491e-01 4.34654591e-01\n",
      " 4.42267899e-01 4.39647852e-01 4.27043714e-01 4.13101664e-01\n",
      " 3.87186833e-01 3.37373602e-01 2.76279228e-01 2.01534306e-01\n",
      " 1.19962980e-01 5.27047453e-02 1.39835080e-02 5.21695277e-03\n",
      " 1.00000000e+00 1.00000000e+00 2.08103766e-02 4.72963338e-02\n",
      " 1.21677627e-01 2.21373004e-01 2.96438533e-01 3.49152617e-01\n",
      " 3.83963547e-01 4.03023843e-01 4.07890084e-01 4.13041744e-01\n",
      " 4.26319718e-01 4.37864108e-01 4.40324573e-01 4.36996002e-01\n",
      " 4.37603482e-01 4.32547665e-01 4.28884026e-01 4.20565802e-01\n",
      " 3.88941320e-01 3.35701010e-01 2.67423506e-01 1.87580297e-01\n",
      " 1.10794790e-01 4.91566073e-02 8.61804720e-03 6.32823089e-03\n",
      " 1.00000000e+00 4.94092936e-03 2.33570305e-02 6.43782193e-02\n",
      " 1.39173512e-01 2.33717674e-01 3.04229852e-01 3.53495699e-01\n",
      " 3.83502442e-01 3.97329212e-01 4.05685846e-01 4.13221866e-01\n",
      " 4.20700035e-01 4.30702305e-01 4.35540285e-01 4.36882439e-01\n",
      " 4.35448234e-01 4.33728832e-01 4.35012916e-01 4.23156730e-01\n",
      " 3.83963843e-01 3.22642860e-01 2.48976273e-01 1.68415514e-01\n",
      " 1.00333843e-01 5.43854364e-02 2.08860162e-02 3.96058642e-03\n",
      " 1.00000000e+00 9.99949977e-03 2.48139553e-02 7.65987311e-02\n",
      " 1.51549783e-01 2.40263322e-01 3.13378820e-01 3.63672472e-01\n",
      " 3.91617971e-01 4.07011369e-01 4.18254214e-01 4.23891240e-01\n",
      " 4.28233691e-01 4.33987401e-01 4.39246661e-01 4.37738456e-01\n",
      " 4.34648181e-01 4.40517941e-01 4.35982247e-01 4.15112303e-01\n",
      " 3.66409773e-01 2.98660659e-01 2.24914062e-01 1.51709849e-01\n",
      " 9.47157453e-02 5.25319390e-02 1.75189792e-02 7.84274502e-04\n",
      " 1.00000000e+00 1.41169427e-03 2.61317080e-02 7.85970784e-02\n",
      " 1.48738833e-01 2.33597004e-01 3.11593948e-01 3.66683159e-01\n",
      " 4.01584364e-01 4.20461419e-01 4.32255607e-01 4.36057313e-01\n",
      " 4.38746290e-01 4.35310411e-01 4.37465443e-01 4.36547835e-01\n",
      " 4.36771499e-01 4.40178720e-01 4.24282445e-01 3.88765034e-01\n",
      " 3.30268281e-01 2.58840437e-01 1.88009686e-01 1.28106146e-01\n",
      " 8.00167204e-02 4.13261745e-02 1.29214607e-02 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.50528858e-02 7.57980636e-02\n",
      " 1.33563413e-01 2.11725085e-01 2.91220716e-01 3.58126584e-01\n",
      " 4.02374971e-01 4.28361157e-01 4.39371584e-01 4.39076584e-01\n",
      " 4.36720365e-01 4.32590617e-01 4.33174377e-01 4.35147753e-01\n",
      " 4.36255844e-01 4.28202874e-01 3.95773973e-01 3.42354225e-01\n",
      " 2.74874587e-01 2.04781846e-01 1.43645561e-01 1.01605912e-01\n",
      " 6.14724608e-02 2.48389862e-02 1.21946622e-02 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.41426554e-02 5.48676849e-02\n",
      " 9.94938525e-02 1.69392430e-01 2.44675896e-01 3.19433821e-01\n",
      " 3.79640008e-01 4.20423783e-01 4.40214381e-01 4.44620242e-01\n",
      " 4.42857734e-01 4.40065215e-01 4.40911769e-01 4.38918559e-01\n",
      " 4.26256207e-01 3.93338098e-01 3.42113324e-01 2.75671899e-01\n",
      " 2.04321649e-01 1.47243092e-01 1.01177912e-01 7.06387302e-02\n",
      " 4.35084260e-02 2.27217456e-02 5.89008406e-03 1.00000000e+00\n",
      " 1.00000000e+00 9.41129456e-04 8.40025626e-03 2.94494774e-02\n",
      " 6.13202738e-02 1.10650528e-01 1.69910538e-01 2.43312141e-01\n",
      " 3.13883962e-01 3.68667827e-01 4.05511450e-01 4.25354904e-01\n",
      " 4.33670482e-01 4.33101913e-01 4.27126396e-01 4.11156441e-01\n",
      " 3.78277461e-01 3.27429615e-01 2.65211652e-01 1.97789190e-01\n",
      " 1.43695965e-01 9.97551774e-02 6.76801181e-02 4.51803587e-02\n",
      " 1.89864490e-02 1.30170031e-02 3.92137273e-05 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.43461626e-02\n",
      " 3.20016160e-02 6.22062682e-02 9.43964861e-02 1.47135261e-01\n",
      " 2.07711838e-01 2.61540700e-01 3.05566409e-01 3.33598924e-01\n",
      " 3.52076868e-01 3.55143994e-01 3.47160646e-01 3.22532147e-01\n",
      " 2.85737195e-01 2.37373407e-01 1.83358047e-01 1.39362322e-01\n",
      " 9.84949046e-02 6.19068563e-02 3.90217400e-02 2.30375899e-02\n",
      " 6.23562779e-03 1.56854909e-04 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.03597009e-03\n",
      " 1.81531774e-02 3.49625651e-02 5.73661971e-02 9.04495102e-02\n",
      " 1.28319946e-01 1.62553571e-01 1.91921859e-01 2.16944260e-01\n",
      " 2.29532506e-01 2.33402260e-01 2.28365316e-01 2.08011339e-01\n",
      " 1.84542570e-01 1.51982495e-01 1.15424954e-01 8.86462762e-02\n",
      " 6.44580955e-02 4.39654028e-02 2.56199992e-02 1.47890315e-02\n",
      " 5.39337628e-03 2.66653347e-03 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.59235932e-03 1.73956829e-02 3.61849980e-02 5.57618836e-02\n",
      " 7.63267649e-02 9.51843023e-02 1.09926543e-01 1.24847753e-01\n",
      " 1.35958669e-01 1.39128049e-01 1.31982446e-01 1.18918873e-01\n",
      " 1.07014571e-01 8.69125171e-02 6.33285565e-02 5.01573550e-02\n",
      " 3.99634204e-02 2.95012809e-02 1.69934069e-02 1.21152354e-02\n",
      " 8.84682886e-04 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 6.49077769e-04 1.06630675e-02\n",
      " 1.68037801e-02 1.95639733e-02 2.20387273e-02 2.10691300e-02\n",
      " 2.98463506e-02 3.63691663e-02 3.99266934e-02 4.08220852e-02\n",
      " 3.82334759e-02 2.76488583e-02 2.22504534e-02 2.24932763e-02\n",
      " 9.48973697e-03 2.35282364e-04 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# standard scores for the columns... along axis 0\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X_test1))\n",
    "# show standardization constants being employed\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)\n",
    "\n",
    "# the model data will be standardized form of preliminary model data\n",
    "X_test = scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 s, sys: 2.89 s, total: 26.5 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf1 = tf.estimator.DNNClassifier(hidden_units=[10,10], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn1 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf1.train(input_fn=input_fn1)\n",
    "duration1 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.92698336,\n",
       " 'average_loss': 0.25567007,\n",
       " 'loss': 32.708324,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (2a)\n",
    "train1_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train1 = dnn_clf1.evaluate(input_fn=train1_input_fn)\n",
    "eval_results_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_train = eval_results_train1['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9194,\n",
       " 'average_loss': 0.27792758,\n",
       " 'loss': 35.180706,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (2a)\n",
    "test1_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test1 = dnn_clf1.evaluate(input_fn=test1_input_fn)\n",
    "eval_results_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 3.17 s, total: 30.6 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf2 = tf.estimator.DNNClassifier(hidden_units=[20,20], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn2 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf2.train(input_fn=input_fn2)\n",
    "duration2 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9676,\n",
       " 'average_loss': 0.11114275,\n",
       " 'loss': 14.218689,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (2b)\n",
    "train2_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train2 = dnn_clf2.evaluate(input_fn=train2_input_fn)\n",
    "eval_results_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9579,\n",
       " 'average_loss': 0.15060125,\n",
       " 'loss': 19.06345,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (2b)\n",
    "test2_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test2 = dnn_clf2.evaluate(input_fn=test2_input_fn)\n",
    "eval_results_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 3.57 s, total: 30.5 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf3 = tf.estimator.DNNClassifier(hidden_units=[10,10,10,10,10], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn3 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf3.train(input_fn=input_fn3)\n",
    "duration3 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9221,\n",
       " 'average_loss': 0.2765352,\n",
       " 'loss': 35.37764,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train3_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train3 = dnn_clf3.evaluate(input_fn=train3_input_fn)\n",
    "eval_results_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9073,\n",
       " 'average_loss': 0.32084632,\n",
       " 'loss': 40.613457,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test3_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test3 = dnn_clf3.evaluate(input_fn=test3_input_fn)\n",
    "eval_results_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 s, sys: 3.92 s, total: 34.9 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf4 = tf.estimator.DNNClassifier(hidden_units=[20,20,20,20,20], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn4 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf4.train(input_fn=input_fn4)\n",
    "duration4 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9676667,\n",
       " 'average_loss': 0.10853379,\n",
       " 'loss': 13.88492,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train4_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train4 = dnn_clf4.evaluate(input_fn=train4_input_fn)\n",
    "eval_results_train4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9499,\n",
       " 'average_loss': 0.18247624,\n",
       " 'loss': 23.098257,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test4_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test4 = dnn_clf4.evaluate(input_fn=test4_input_fn)\n",
    "eval_results_test4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 8.21 s, total: 2min 5s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf5 = tf.estimator.DNNClassifier(hidden_units=[300,300], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn5 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf5.train(input_fn=input_fn5)\n",
    "duration5 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.99975,\n",
       " 'average_loss': 0.0028068793,\n",
       " 'loss': 0.35908905,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train5_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train5 = dnn_clf5.evaluate(input_fn=train5_input_fn)\n",
    "eval_results_train5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9796,\n",
       " 'average_loss': 0.09115615,\n",
       " 'loss': 11.538753,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test5_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test5 = dnn_clf5.evaluate(input_fn=test5_input_fn)\n",
    "eval_results_test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 11 s, total: 2min 47s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf6 = tf.estimator.DNNClassifier(hidden_units=[300,300,300], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn6 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf6.train(input_fn=input_fn6)\n",
    "duration6 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9996333,\n",
       " 'average_loss': 0.0023298624,\n",
       " 'loss': 0.29806343,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train6_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train6 = dnn_clf6.evaluate(input_fn=train6_input_fn)\n",
    "eval_results_train6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9732,\n",
       " 'average_loss': 0.15157129,\n",
       " 'loss': 19.18624,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test6_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test6 = dnn_clf6.evaluate(input_fn=test6_input_fn)\n",
    "eval_results_test6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 5.92 s, total: 1min 9s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf7 = tf.estimator.DNNClassifier(hidden_units=[150,150], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn7 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf7.train(input_fn=input_fn7)\n",
    "duration7 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9992833,\n",
       " 'average_loss': 0.0053068018,\n",
       " 'loss': 0.6789085,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train7_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train7 = dnn_clf7.evaluate(input_fn=train7_input_fn)\n",
    "eval_results_train7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9768,\n",
       " 'average_loss': 0.102281146,\n",
       " 'loss': 12.94698,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test7_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test7 = dnn_clf7.evaluate(input_fn=test7_input_fn)\n",
    "eval_results_test7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 7.35 s, total: 1min 22s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.process_time()\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf8 = tf.estimator.DNNClassifier(hidden_units=[150,150,150], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "input_fn8 = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=20, batch_size=100, shuffle=True)\n",
    "dnn_clf8.train(input_fn=input_fn8)\n",
    "duration8 = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.99925,\n",
       " 'average_loss': 0.004428439,\n",
       " 'loss': 0.56653804,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate training accuracy (5a)\n",
    "train8_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "eval_results_train8 = dnn_clf8.evaluate(input_fn=train8_input_fn)\n",
    "eval_results_train8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9762,\n",
       " 'average_loss': 0.12706533,\n",
       " 'loss': 16.084219,\n",
       " 'global_step': 12000}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate test accuracy (5a)\n",
    "test8_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "eval_results_test8 = dnn_clf8.evaluate(input_fn=test8_input_fn)\n",
    "eval_results_test8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_train = eval_results_train1['accuracy']\n",
    "a1_test = eval_results_test1['accuracy']\n",
    "a2_train = eval_results_train2['accuracy']\n",
    "a2_test = eval_results_test2['accuracy']\n",
    "a3_train = eval_results_train3['accuracy']\n",
    "a3_test = eval_results_test3['accuracy']\n",
    "a4_train = eval_results_train4['accuracy']\n",
    "a4_test = eval_results_test4['accuracy']\n",
    "a5_train = eval_results_train5['accuracy']\n",
    "a5_test = eval_results_test5['accuracy']\n",
    "a6_train = eval_results_train6['accuracy']\n",
    "a6_test = eval_results_test6['accuracy']\n",
    "a7_train = eval_results_train7['accuracy']\n",
    "a7_test = eval_results_test7['accuracy']\n",
    "a8_train = eval_results_train8['accuracy']\n",
    "a8_test = eval_results_test8['accuracy']\n",
    "\n",
    "def convert(seconds): \n",
    "    seconds = seconds % (24 * 3600) \n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "      \n",
    "    return \"%02d:%02d\" % (minutes, seconds)\n",
    "\n",
    "d1 = convert(duration1)\n",
    "d2 = convert(duration2)\n",
    "d3 = convert(duration3)\n",
    "d4 = convert(duration4)\n",
    "d5 = convert(duration5)\n",
    "d6 = convert(duration6)\n",
    "d7 = convert(duration7)\n",
    "d8 = convert(duration8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number Of Layers</th>\n",
       "      <th>Nodes Per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>00:26</td>\n",
       "      <td>0.926983</td>\n",
       "      <td>0.9194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>0.9579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>00:30</td>\n",
       "      <td>0.922100</td>\n",
       "      <td>0.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>00:34</td>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>02:05</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 6</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>02:47</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 7</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>01:09</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.9768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 8</th>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>01:22</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.9762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Number Of Layers  Nodes Per Layer Processing Time  \\\n",
       "Model 1                 2               10           00:26   \n",
       "Model 2                 2               20           00:30   \n",
       "Model 3                 5               10           00:30   \n",
       "Model 4                 5               20           00:34   \n",
       "Model 5                 2              300           02:05   \n",
       "Model 6                 3              300           02:47   \n",
       "Model 7                 2              150           01:09   \n",
       "Model 8                 3              150           01:22   \n",
       "\n",
       "         Training Set Accuracy  Test Set Accuracy  \n",
       "Model 1               0.926983             0.9194  \n",
       "Model 2               0.967600             0.9579  \n",
       "Model 3               0.922100             0.9073  \n",
       "Model 4               0.967667             0.9499  \n",
       "Model 5               0.999750             0.9796  \n",
       "Model 6               0.999633             0.9732  \n",
       "Model 7               0.999283             0.9768  \n",
       "Model 8               0.999250             0.9762  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Number Of Layers\": [2, 2, 5, 5, 2, 3, 2, 3],\n",
    "        \"Nodes Per Layer\": [10, 20, 10, 20, 300, 300, 150, 150],\n",
    "        \"Processing Time\": [d1, d2, d3, d4, d5, d6, d7, d8],\n",
    "        \"Training Set Accuracy\": [a1_train, a2_train, a3_train, a4_train, a5_train, a6_train, a7_train, a8_train],\n",
    "        \"Test Set Accuracy\": [a1_test, a2_test, a3_test, a4_test, a5_test, a6_test, a7_test, a8_test]\n",
    "    },\n",
    "    index=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\", \"Model 5\", \"Model 6\", \"Model 7\", \"Model 8\"]\n",
    ")\n",
    "\n",
    "nn_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
