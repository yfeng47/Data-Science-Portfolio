{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "\n",
      "Input:\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "\n",
      "Target:\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "\n",
      " Total SSE by Iteration\n",
      "\n",
      "   0. 2.0623\n",
      " 100. 2.0004\n",
      " 200. 2.0003\n",
      " 300. 2.0004\n",
      " 400. 1.9996\n",
      " 500. 1.9974\n",
      " 600. 1.9838\n",
      " 700. 1.8977\n",
      " 800. 1.6345\n",
      " 900. 1.4576\n",
      "1000. 1.3782\n",
      "1100. 1.2831\n",
      "1200. 1.0052\n",
      "1300. 0.4354\n",
      "1400. 0.1951\n",
      "1500. 0.1151\n",
      "1600. 0.0794\n",
      "1700. 0.0599\n",
      "\n",
      "------------\n",
      "\n",
      "Input array:\n",
      "[0 0]\n",
      "\n",
      "Target array\n",
      "[0 1]\n",
      "\n",
      "Weights (first row corresponds to first output):\n",
      "[array([[-4.26780679, -4.27825257],\n",
      "       [-6.50177003, -6.59680989]]), array([[ 6.10839383, -6.47054433],\n",
      "       [-6.20770112,  6.57469073]])]\n",
      "\n",
      "Biases:\n",
      "[array([6.26681704, 2.51723276]), array([-2.76119179,  2.80705311])]\n",
      "\n",
      "Output Layer Final Output:\n",
      "[0.06587619 0.93672771]\n",
      "\n",
      "------------\n",
      "\n",
      "Input array:\n",
      "[0 1]\n",
      "\n",
      "Target array\n",
      "[1 0]\n",
      "\n",
      "Weights (first row corresponds to first output):\n",
      "[array([[-4.26780679, -4.27825257],\n",
      "       [-6.50177003, -6.59680989]]), array([[ 6.10839383, -6.47054433],\n",
      "       [-6.20770112,  6.57469073]])]\n",
      "\n",
      "Biases:\n",
      "[array([6.26681704, 2.51723276]), array([-2.76119179,  2.80705311])]\n",
      "\n",
      "Output Layer Final Output:\n",
      "[0.92442674 0.07284226]\n",
      "\n",
      "------------\n",
      "\n",
      "Input array:\n",
      "[1 0]\n",
      "\n",
      "Target array\n",
      "[1 0]\n",
      "\n",
      "Weights (first row corresponds to first output):\n",
      "[array([[-4.26780679, -4.27825257],\n",
      "       [-6.50177003, -6.59680989]]), array([[ 6.10839383, -6.47054433],\n",
      "       [-6.20770112,  6.57469073]])]\n",
      "\n",
      "Biases:\n",
      "[array([6.26681704, 2.51723276]), array([-2.76119179,  2.80705311])]\n",
      "\n",
      "Output Layer Final Output:\n",
      "[0.92416058 0.07310363]\n",
      "\n",
      "------------\n",
      "\n",
      "Input array:\n",
      "[1 1]\n",
      "\n",
      "Target array\n",
      "[0 1]\n",
      "\n",
      "Weights (first row corresponds to first output):\n",
      "[array([[-4.26780679, -4.27825257],\n",
      "       [-6.50177003, -6.59680989]]), array([[ 6.10839383, -6.47054433],\n",
      "       [-6.20770112,  6.57469073]])]\n",
      "\n",
      "Biases:\n",
      "[array([6.26681704, 2.51723276]), array([-2.76119179,  2.80705311])]\n",
      "\n",
      "Output Layer Final Output:\n",
      "[0.10027702 0.90298085]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Training XOR Model using numpy - Yining Feng.\n",
    "\n",
    "Assumptions:\n",
    "    * Assumes sigmoid transfer function with alpha=1\n",
    "    * Assumes a single layer of hidden nodes\n",
    "    * Assumes batch size is fixed at 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Random number generating seed for reproducible results\n",
    "np.random.seed(9798)\n",
    "\n",
    "\n",
    "class NeuralNet:\n",
    "    \"\"\"Describes a neural network of the type used in this example.\"\"\"\n",
    "\n",
    "    def __init__(self, case_input, weights, biases, net0, out0, net1, out1):\n",
    "        \"\"\"Create starting parts of the neural net.\"\"\"\n",
    "        self.case_input = case_input\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        self.net0 = net0\n",
    "        self.out0 = out0\n",
    "        self.net1 = net1\n",
    "        self.out1 = out1\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"Print information about the neural network.\"\"\"\n",
    "        print(\"Input array:\")\n",
    "        print(self.case_input)\n",
    "        print(\"\\nWeights (first row corresponds to first output):\")\n",
    "        print(self.weights)\n",
    "        print(\"\\nBiases:\")\n",
    "        print(self.biases)\n",
    "        print(\"\\nHidden Layer Net:\")\n",
    "        print(self.net0)\n",
    "        print(\"\\nHidden Layer Output:\")\n",
    "        print(self.out0)\n",
    "        print(\"\\nOutput Layer Net:\")\n",
    "        print(self.net1)\n",
    "        print(\"\\nOutput Layer Final Output:\")\n",
    "        print(self.out1)\n",
    "\n",
    "\n",
    "class Backprop:\n",
    "    \"\"\"Describes the results of backpropagation.\"\"\"\n",
    "\n",
    "    def __init__(self, target, eta, delta0, delta1, weights_new, biases_new):\n",
    "        \"\"\"Create starting parts of the backprop.\"\"\"\n",
    "        self.target = target\n",
    "        self.eta = eta\n",
    "        self.delta0 = delta0\n",
    "        self.delta1 = delta1\n",
    "        self.weights_new = weights_new\n",
    "        self.biases_new = biases_new\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"Print information about the backpropagation.\"\"\"\n",
    "        print(\"Target:\")\n",
    "        print(self.target)\n",
    "        print(f\"\\nEta (learning rate): {self.eta}\")\n",
    "        print(\"\\nDelta 0 (closest to output):\")\n",
    "        print(self.delta0)\n",
    "        print(\"\\nDelta 1 (closest to input):\")\n",
    "        print(self.delta1)\n",
    "        print(\"\\nNew Weights (first row corresponds to first output):\")\n",
    "        print(self.weights_new)\n",
    "        print(\"\\n Biases (unchanged):\")\n",
    "        print(self.biases_new)\n",
    "\n",
    "\n",
    "def sigmoid_transfer(net_sum):\n",
    "    \"\"\"Calculate the sigmoid transfer function.\n",
    "\n",
    "    Args:\n",
    "        net_sum: the input into the node.\n",
    "    Returns:\n",
    "        the activation output of the node.\n",
    "    Raises:\n",
    "        TypeError: if net_sum is not a number.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-net_sum))\n",
    "\n",
    "\n",
    "def initial_weights(input_dim, hidden_nodes, output_dim):\n",
    "    \"\"\"Randomly assigns initial weights [-1, 1).\n",
    "\n",
    "    Args:\n",
    "        input_dim: number of inputs\n",
    "        hidden_nodes: number of hidden_nodes\n",
    "        output_dim: number of output classes\n",
    "    Returns:\n",
    "        list of initial weight arrays\n",
    "\n",
    "    \"\"\"\n",
    "    input_to_hidden = np.random.uniform(-1, 1, (hidden_nodes, input_dim))\n",
    "    hidden_to_output = np.random.uniform(-1, 1, (output_dim, hidden_nodes))\n",
    "    return [input_to_hidden, hidden_to_output]\n",
    "\n",
    "\n",
    "def initial_biases(hidden_nodes, output_dim):\n",
    "    \"\"\"Randomly assigns initial biases [-1, 1).\n",
    "\n",
    "    Args:\n",
    "        hidden_nodes: number of hidden_nodes\n",
    "        output_dim: number of output classes\n",
    "    Returns:\n",
    "        list of initial weight arrays\n",
    "\n",
    "    \"\"\"\n",
    "    input_to_hidden = np.random.uniform(-1, 1, hidden_nodes)\n",
    "    hidden_to_output = np.random.uniform(-1, 1, output_dim)\n",
    "    return [input_to_hidden, hidden_to_output]\n",
    "\n",
    "\n",
    "def forward_pass(case_input, size,\n",
    "                 weights=None,\n",
    "                 biases=None,\n",
    "                 verbose=False):\n",
    "    \"\"\"Calculate the result of a forward pass through the neural network.\n",
    "\n",
    "    Args:\n",
    "        case_input: array of input into the neural network\n",
    "        size: tuple of input size, hidden nodes, and output classes\n",
    "        weights: array of network weights (default None)\n",
    "        biases: array of network biases (default None)\n",
    "        verbose: if true, prints full results (default False)\n",
    "    Returns:\n",
    "        a neural network (NeuralNet object) containing results\n",
    "    Raises:\n",
    "        TypeError: if arguments are not arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    # If not supplied, generate random weights\n",
    "    if weights is None:\n",
    "        weights = initial_weights(size[0], size[1], size[2])\n",
    "    if biases is None:\n",
    "        biases = initial_biases(size[1], size[2])\n",
    "\n",
    "    # Check input types\n",
    "    if not isinstance(case_input, np.ndarray):\n",
    "        raise TypeError(\"case_input must be an array\")\n",
    "    if not isinstance(size, tuple):\n",
    "        raise TypeError(\"case_input must be an array\")\n",
    "    if not isinstance(weights[0], np.ndarray):\n",
    "        raise TypeError(\"weights must be an array\")\n",
    "    if not isinstance(biases[0], np.ndarray):\n",
    "        raise TypeError(\"biases must be an array\")\n",
    "\n",
    "    # Calculate the summed input to the hidden layer\n",
    "    net0 = np.matmul(case_input, np.transpose(weights[0])) + biases[0]\n",
    "\n",
    "    # Apply sigmoid transfer function\n",
    "    out0 = sigmoid_transfer(net0)\n",
    "\n",
    "    # Calculate the summed input to the output layer\n",
    "    net1 = np.matmul(out0, np.transpose(weights[1])) + biases[1]\n",
    "\n",
    "    # Apply sigmoid transfer function\n",
    "    out1 = sigmoid_transfer(net1)\n",
    "\n",
    "    forpass = NeuralNet(case_input, weights, biases, net0, out0, net1, out1)\n",
    "\n",
    "    if verbose:\n",
    "        forpass.describe()\n",
    "\n",
    "    return forpass\n",
    "\n",
    "\n",
    "def sse_eval(target, network, verbose=False):\n",
    "    \"\"\"Calculate the sum of squared errors for a neural network.\n",
    "\n",
    "    Args:\n",
    "        target: array of ideal output\n",
    "        network: NeuralNet object\n",
    "        verbose: if true, print result (default False)\n",
    "    Returns:\n",
    "        sum of squared errors from the network\n",
    "    Raises:\n",
    "        TypeError: if arguments are not an array and a NeuralNet.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check input types\n",
    "    if not isinstance(target, np.ndarray):\n",
    "        raise TypeError(\"target must be an array\")\n",
    "    if not isinstance(network, NeuralNet):\n",
    "        raise TypeError(\"network must be a NeuralNet\")\n",
    "\n",
    "    sse = np.sum((target - network.out1)**2)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total SSE = {sse:.4f}\")\n",
    "\n",
    "    return sse\n",
    "\n",
    "\n",
    "def backpropagation(target, network, eta, verbose=False):\n",
    "    \"\"\"Conducts a step of backpropagation.\n",
    "\n",
    "    Args:\n",
    "        target: array of ideal output\n",
    "        network: NeuralNet object\n",
    "        eta: learning rate\n",
    "        verbose: if true, print result of backpropagation (default False)\n",
    "    Returns:\n",
    "        results of backpropagation (a Backprop object)\n",
    "    Raises:\n",
    "        TypeError: if arguments are not an array, NeuralNet, and numeric.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if eta is a number\n",
    "    if not isinstance(eta, (int, float)):\n",
    "        raise TypeError(\"eta (learning rate) must be type int or float\")\n",
    "\n",
    "    # Working backwards so delta0 is array of deltas closest to output layer\n",
    "    delta0 = -1*(target - network.out1)*network.out1*(1 - network.out1)\n",
    "\n",
    "    # Adjusted weights from hidden to output layer\n",
    "    weights0 = network.weights[1] - eta*np.outer(delta0, network.out0)\n",
    "\n",
    "    # Adjust bias from hidden to output layer\n",
    "    biases0 = network.biases[1] - eta*delta0\n",
    "\n",
    "    # Working backwards so delta1 is array of deltas closest to input layer\n",
    "    summation = np.sum(np.transpose(network.weights[1])*delta0, axis=1)\n",
    "    delta1 = summation*network.out0*(1 - network.out0)\n",
    "\n",
    "    # Adjusted weights from input to hidden layer\n",
    "    weights1 = network.weights[0] - eta*np.outer(delta1, network.case_input)\n",
    "\n",
    "    # Adjust bias from input to hidden layer\n",
    "    biases1 = network.biases[0] - eta*delta1\n",
    "\n",
    "    # Create a new weights array containing all weights\n",
    "    weights_new = [weights1, weights0]\n",
    "\n",
    "    # Create a new biases array containing all biases\n",
    "    biases_new = [biases1, biases0]\n",
    "\n",
    "    bprop = Backprop(target, eta, delta0, delta1, weights_new, biases_new)\n",
    "\n",
    "    if verbose:\n",
    "        bprop.describe()\n",
    "\n",
    "    return bprop\n",
    "\n",
    "\n",
    "def train_xor(case_input, target, size,\n",
    "              eta=0.5, epsilon=0.05, iterations=5000,\n",
    "              verbose=True):\n",
    "    \"\"\"Trains the XOR model and then predicts target.\n",
    "\n",
    "    Assumptions:\n",
    "        For each iteration (epoch) all input records are used in random order\n",
    "\n",
    "    Args:\n",
    "        case_input: array of input data (four observations)\n",
    "        target: array of target output (four observations)\n",
    "        size: tuple of input size, hidden nodes, and output classes\n",
    "        eta: learning rate (default 0.5)\n",
    "        epsilon: early stopping criteria SSE (default 0.05)\n",
    "        iterations: number of maximum training iterations (default 5000)\n",
    "        verbose: if true, print results (default True)\n",
    "    Returns:\n",
    "        a neural network object (NeuralNet) containing trained results\n",
    "    Raises:\n",
    "        TypeError: if epsilon is not a float.\n",
    "        ValueError: if the number of iterations is less than or equal to 0.\n",
    "\n",
    "    \"\"\"\n",
    "    # Check if epsilon a float\n",
    "    if not isinstance(epsilon, float):\n",
    "        raise TypeError(\"epsilon (learning rate) must be type float\")\n",
    "\n",
    "    # Check iterations value\n",
    "    if iterations <= 0:\n",
    "        raise ValueError(\"number of iterations must be greater than 0\")\n",
    "\n",
    "    # Calculate a baseline SSE\n",
    "    sse = 0\n",
    "    for i in range(0, case_input.shape[0]):\n",
    "        case_input_single = case_input[i]\n",
    "        target_single = target[i]\n",
    "        fit = forward_pass(case_input_single, size)\n",
    "        sse += sse_eval(target_single, fit)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training Model\")\n",
    "        print(\"\\nInput:\")\n",
    "        print(case_input)\n",
    "        print(\"\\nTarget:\")\n",
    "        print(target)\n",
    "        print(\"\\n Total SSE by Iteration\")\n",
    "        print(f\"\\n{0:4}. {sse:.4f}\")\n",
    "\n",
    "    # Train over the specified number of iterations\n",
    "    for iteration_num in range(1, iterations+1):\n",
    "        # Perform backpropagation for each training record\n",
    "        shuffle = np.random.choice(case_input.shape[0],\n",
    "                                   case_input.shape[0],\n",
    "                                   replace=False)\n",
    "        for i in shuffle:\n",
    "            case_input_single = case_input[i]\n",
    "            target_single = target[i]\n",
    "            fit = forward_pass(case_input_single, size,\n",
    "                               weights=fit.weights,\n",
    "                               biases=fit.biases)\n",
    "            backprop = backpropagation(target_single, fit, eta)\n",
    "            fit = forward_pass(case_input_single, size,\n",
    "                               weights=backprop.weights_new,\n",
    "                               biases=backprop.biases_new)\n",
    "        # Calculate total SSE for the iteration\n",
    "        sse = 0\n",
    "        for i in range(0, case_input.shape[0]):\n",
    "            case_input_single = case_input[i]\n",
    "            target_single = target[i]\n",
    "            fit = forward_pass(case_input_single, size,\n",
    "                               weights=backprop.weights_new,\n",
    "                               biases=backprop.biases_new)\n",
    "            sse += sse_eval(target_single, fit)\n",
    "        if verbose and iteration_num % 100 == 0:\n",
    "            print(f\"{iteration_num:4}. {sse:.4f}\")\n",
    "\n",
    "        # Enable early stopping past the threshold set\n",
    "        if sse <= epsilon or iteration_num == iterations:\n",
    "            if verbose:\n",
    "                for i in range(0, case_input.shape[0]):\n",
    "                    case_input_single = case_input[i]\n",
    "                    target_single = target[i]\n",
    "                    fit = forward_pass(case_input_single, size,\n",
    "                                       weights=backprop.weights_new,\n",
    "                                       biases=backprop.biases_new)\n",
    "                    print(\"\\n------------\")\n",
    "                    print(\"\\nInput array:\")\n",
    "                    print(fit.case_input)\n",
    "                    print(\"\\nTarget array\")\n",
    "                    print(target_single)\n",
    "                    print(\"\\nWeights (first row corresponds to first output):\")\n",
    "                    print(fit.weights)\n",
    "                    print(\"\\nBiases:\")\n",
    "                    print(fit.biases)\n",
    "                    print(\"\\nOutput Layer Final Output:\")\n",
    "                    print(fit.out1)\n",
    "            break\n",
    "\n",
    "    return fit\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_xor(np.array([[0, 0], [0, 1], [1, 0], [1, 1]]),\n",
    "              np.array([[0, 1], [1, 0], [1, 0], [0, 1]]),\n",
    "              (2, 2, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
